{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## siRNA knockdown calibrated ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fits analytical functions to Rafał’s data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "siRNA (small interfering RNA) triggers specific degradation of mRNA. The RISC (RNA-induced silencing complex), which consists of siRNA and some proteins, cuts mRNA containing a strand sequence complementary to the sequence of the siRNA. Reducing protein expression by adding siRNA is called gene knockdown.\n",
    "\n",
    "Gene knockdown is a promising approach for the treatment of some diseases, e.g. cancer. The aim of this project is to study the influence of siRNA on gene expression and mRNA degradation on the single cell level to promote development of siRNA-based medical treatments.\n",
    "\n",
    "This is done by fitting the solutions of the differential equations describing the expression network to measured fluorescence traces of cells transfected with a GFP mRNA and a RFP mRNA, where siRNA specific for GFP mRNA is added and RFP is used as a reference.\n",
    "\n",
    "Among the fit parameters, there is the GFP mRNA degradation rate $\\delta_\\text{g}$ and the RFP mRNA degradation rate $\\delta_\\text{r}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solutions look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_\\text{red}(t) =\n",
    "m_\\text{r}\\,k_\\text{tl} \\left(\n",
    "\\frac{1}{\\beta_\\text{r}-\\delta_\\text{r}+k_\\text{m,r}} \\mathrm{e}^{-(\\beta_\\text{r}+k_\\text{m,r})(t-t_0)}\n",
    "-\\frac{1}{\\beta_\\text{r} - \\delta_\\text{r}} \\mathrm{e}^{-\\beta_\\text{r} (t-t_0)}\n",
    "+\\frac{k_\\text{m,r}}{(\\beta_\\text{r}-\\delta_\\text{r}) (\\beta_\\text{r}-\\delta_\\text{r}+k_\\text{m,r})} \\mathrm{e}^{-\\delta_\\text{r} (t-t_0)}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_\\text{green}(t) =\n",
    "m_\\text{g}\\,k_\\text{tl} \\left(\n",
    "\\frac{1}{\\beta_\\text{g}-\\delta_\\text{g}+k_\\text{m,g}} \\mathrm{e}^{-(\\beta_\\text{g}+k_\\text{m,g})(t-t_0)}\n",
    "-\\frac{1}{\\beta_\\text{g} - \\delta_\\text{g}} \\mathrm{e}^{-\\beta_\\text{g} (t-t_0)}\n",
    "+\\frac{k_\\text{m,g}}{(\\beta_\\text{g}-\\delta_\\text{g}) (\\beta_\\text{g}-\\delta_\\text{g}+k_\\text{m,g})} \\mathrm{e}^{-\\delta_\\text{g} (t-t_0)}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook structure\n",
    "The notebook has the following structure:\n",
    "\n",
    "At first, the model functions are defined and the data is loaded. The next section contains code for fitting the two models separately. The next section contains code for fitting the two traces in one run with parameters shared among the models.\n",
    "\n",
    "Fitting requires that the result list `R` is defined, which can be done by running the corresponding cell. When `R` has been populated by fitting, the results can be plotted. There are cells for plotting the results of the separate fit, the results of the combined fit, and the pure parameter distributions of all fits.\n",
    "\n",
    "Additionally, there are cells for saving and loading paramaters by python’s `pickle` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules needed\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.seterr(divide='print')\n",
    "import scipy as sc\n",
    "import lmfit as lm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from io_Daniel import *\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import pickle\n",
    "import ipywidgets as wdg\n",
    "import IPython\n",
    "from collections import OrderedDict\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def red(t, tr, m_ktl, kmr, betr, deltr, offr):\n",
    "    \"\"\"Model function for red data\"\"\"\n",
    "\n",
    "    f = np.zeros(np.shape(t))\n",
    "    idx_after = (t > tr)\n",
    "    dt = t[idx_after] - tr\n",
    "\n",
    "    f1 = np.exp(- (betr + kmr) * dt) / (betr - deltr + kmr)\n",
    "    f2 = - np.exp(- betr * dt) / (betr - deltr)\n",
    "    f3 = kmr * np.exp(- deltr * dt) / (betr - deltr) / (betr - deltr + kmr)\n",
    "\n",
    "    f[idx_after] = (f1 + f2 + f3) * m_ktl\n",
    "\n",
    "    return f + offr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def green(t, tg, m_ktl, kmg, betg, deltg, offg):\n",
    "    \"\"\"Model function for green data\"\"\"\n",
    "\n",
    "    f = np.zeros(np.shape(t))\n",
    "    idx_after = t > tg\n",
    "    dt = t[idx_after] - tg\n",
    "\n",
    "    f1 = np.exp(- (betg + kmg) * dt) / (betg - deltg + kmg)\n",
    "    f2 = - np.exp(- betg * dt) / (betg - deltg)\n",
    "    f3 = kmg * np.exp(- deltg * dt) / (betg - deltg) / (betg - deltg + kmg)\n",
    "\n",
    "    f[idx_after] = (f1 + f2 + f3) * m_ktl\n",
    "\n",
    "    return f + offg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined(t, tr, tg, m_ktl, kmr, kmg, betr, betg, deltr, deltg, offr, offg):\n",
    "    \"\"\"Model function for a combined fit of red and green data\"\"\"\n",
    "\n",
    "    f = np.stack(\n",
    "        (red(t=t, tr=tr, m_ktl=m_ktl, kmr=kmr, betr=betr, deltr=deltr, offr=offr),\n",
    "         green(t=t, tg=tg, m_ktl=m_ktl, kmg=kmg, betg=betg, deltg=deltg, offg=offg)),\n",
    "        axis=1)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set default parameter values\n",
    "m_ktl_0 = 2e4\n",
    "\n",
    "tr_0 = 4.5\n",
    "kmr_0 = 0.1\n",
    "betr_0 = 0.3\n",
    "deltr_0 = 0.03\n",
    "offr_0 = 0\n",
    "\n",
    "tg_0 = 2\n",
    "kmg_0 = 0.1\n",
    "betg_0 = 0.04\n",
    "deltg_0 = 2\n",
    "offg_0 = 0\n",
    "\n",
    "MAX_m_ktl = 5e5\n",
    "MAX_tr = 30\n",
    "MAX_tg = 30\n",
    "MAX_kmr = 30\n",
    "MAX_kmg = 30\n",
    "MAX_betr = 10\n",
    "MAX_betg = 10\n",
    "MAX_deltr = 11\n",
    "MAX_deltg = 11\n",
    "\n",
    "MIN_m_ktl = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FitParameters:\n",
    "    \"\"\"FitParameters facilitates managing values and bounds of fit parameters\"\"\"\n",
    "    def __init__(self, fun, independent=[], fixed=[]):\n",
    "        # Store function\n",
    "        self.fun = fun\n",
    "\n",
    "        # Get parameters of fun\n",
    "        params = inspect.signature(self.fun).parameters\n",
    "\n",
    "        # Build data frame of parameters\n",
    "        self.df = pd.DataFrame(columns=['value', 'min', 'max'],\n",
    "                               index=[p for p in params.keys()],\n",
    "                               dtype=np.float64)\n",
    "\n",
    "        # Set “independent” and “fixed” flag\n",
    "        self.df.add(pd.DataFrame(columns=['independent', 'fixed'], dtype=np.bool))\n",
    "        for p in self.df.index.values:\n",
    "            self.df.loc[p, 'independent'] = p in independent\n",
    "            self.df.loc[p, 'fixed'] = p in fixed\n",
    "\n",
    "        # Set default parameters\n",
    "        for p in self.df.index.values:\n",
    "            if params[p].default == inspect.Parameter.empty:\n",
    "                if self.df.loc[p, 'independent']:\n",
    "                    self.df.loc[p, 'value'] = np.NaN\n",
    "                else:\n",
    "                    self.df.loc[p, 'value'] = 0\n",
    "            else:\n",
    "                self.df.loc[p, 'value'] = params[p].default\n",
    "\n",
    "    def set(self, p, **props):\n",
    "        \"\"\"Allows user to change parameter properties\"\"\"\n",
    "        if p not in self.df.index.values:\n",
    "            raise KeyError(\"Unknown parameter name: {}\".format(par))\n",
    "\n",
    "        for prop, val in props.items():\n",
    "            if prop == 'value':\n",
    "                self.df.loc[p, 'value'] = val\n",
    "            elif prop == 'min':\n",
    "                self.df.loc[p, 'min'] = val\n",
    "            elif prop == 'max':\n",
    "                self.df.loc[p, 'max'] = val\n",
    "            elif prop == 'independent':\n",
    "                self.df.loc[p, 'independent'] = val\n",
    "            elif prop == 'fixed':\n",
    "                self.df.loc[p, 'fixed'] = val\n",
    "            else:\n",
    "                raise KeyError(\"Illegal parameter property: {}\".format(prop))\n",
    "\n",
    "    def eval_params(self, params=[], **vals):\n",
    "        \"\"\"Returns parameters for evaluating the function.\n",
    "\n",
    "        Arguments:\n",
    "        params: optional list of values of free parameters\n",
    "        vals: dictionary of parameter values\n",
    "\n",
    "        If a value for a parameter is specified in both `params` and `vals`,\n",
    "        the value from `vals` is used.\n",
    "        Values for independent parameters must be specified in `vals`.\"\"\"\n",
    "        # Add additional values from `params` to vals\n",
    "        if len(params) != 0:\n",
    "            par_names = self.names()\n",
    "            if np.size(par_names) != len(params):\n",
    "                raise ValueError(\"Wrong number of parameters given ({})\".format(len(params)))\n",
    "            for pn, pv in zip(par_names, params):\n",
    "                if pn not in vals:\n",
    "                    vals[pn] = pv\n",
    "\n",
    "        # Fill values unspecified so far from `self.df`\n",
    "        for p in self.df.index.values:\n",
    "            if p not in vals:\n",
    "                if self.df.loc[p, 'independent']:\n",
    "                    raise ValueError(\"Independent parameter `{}` not specified\".format(p))\n",
    "                else:\n",
    "                    vals[p] = self.df.loc[p, 'value']\n",
    "        return vals\n",
    "\n",
    "    def eval(self, params=[], **vals):\n",
    "        \"\"\"Evaluates the function.\n",
    "\n",
    "        Arguments:\n",
    "        params: optional list of values of free parameters\n",
    "        vals: dictionary of parameter values\n",
    "\n",
    "        If a value for a parameter is specified in both `params` and `vals`,\n",
    "        the value from `vals` is used.\n",
    "        Values for independent parameters must be specified in `vals`.\"\"\"\n",
    "        return self.fun(**self.eval_params(params, **vals))\n",
    "\n",
    "    def freeIdx(self):\n",
    "        \"\"\"Returns a list of names of free parameters\"\"\"\n",
    "        return [p for p in self.df.index.values\n",
    "                if not (self.df.loc[p, 'independent'] or self.df.loc[p, 'fixed'])]\n",
    "\n",
    "    def bounds(self):\n",
    "        \"\"\"Returns a list of bound tuples of free parameters\n",
    "        for use in scipy.optimize.minimize\"\"\"\n",
    "        bnds = []\n",
    "        for p in self.freeIdx():\n",
    "            # Get parameter bounds\n",
    "            min_val = self.df.loc[p, 'min']\n",
    "            max_val = self.df.loc[p, 'max']\n",
    "\n",
    "            # Replace missing values with default minimum and maximum values\n",
    "            if np.isnan(min_val):\n",
    "                min_val = None\n",
    "            if np.isnan(max_val):\n",
    "                max_val = None\n",
    "\n",
    "            # Append to bounds list\n",
    "            bnds.append((min_val, max_val))\n",
    "        return bnds\n",
    "\n",
    "    def initial(self):\n",
    "        \"\"\"Returns a numpy.ndarray of initial values for use in scipy.optimize.minimize\"\"\"\n",
    "        return self.df.loc[self.freeIdx(), 'value'].values.copy()\n",
    "\n",
    "    def index(self, p):\n",
    "        \"\"\"Returns the index of a given parameter in the parameter vector\"\"\"\n",
    "        idx = np.flatnonzero(self.df.index.values == p)\n",
    "        if len(idx) == 0:\n",
    "            raise KeyError(\"Unknown parameter name: {}\".format(p))\n",
    "        return idx[0]\n",
    "\n",
    "    def names(self, onlyFree=True):\n",
    "        \"\"\"Returns an array of the parameter names.\n",
    "\n",
    "        If `onlyFree == True`, only free parameters are returned.\n",
    "        Else, all parameters (including independent and fixed parameters) are returned.\"\"\"\n",
    "        if onlyFree:\n",
    "            return np.array(self.freeIdx(), dtype=np.object_)\n",
    "        else:\n",
    "            return self.df.index.values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative separate models for scipy.optimize.minimize\n",
    "red_p = FitParameters(red, independent='t')\n",
    "red_p.set('tr', min=0, max=MAX_tr, value=tr_0)\n",
    "red_p.set('m_ktl', min=MIN_m_ktl, max=MAX_m_ktl, value=m_ktl_0)\n",
    "red_p.set('kmr', min=0, max=MAX_kmr, value=kmr_0)\n",
    "red_p.set('betr', min=0.001, max=MAX_betr, value=betr_0)\n",
    "red_p.set('deltr', min=0.001, max=MAX_deltr, value=deltr_0)\n",
    "red_p.set('offr', value=offr_0)\n",
    "\n",
    "green_p = FitParameters(green, independent='t')\n",
    "green_p.set('tg', min=0, max=MAX_tg, value=tg_0)\n",
    "green_p.set('m_ktl', min=MIN_m_ktl, max=MAX_m_ktl, value=m_ktl_0)\n",
    "green_p.set('kmg', min=0, max=MAX_kmg, value=kmg_0)\n",
    "green_p.set('betg', min=0.001, max=MAX_betg, value=betg_0)\n",
    "green_p.set('deltg', min=0.001, max=MAX_deltg, value=deltg_0)\n",
    "green_p.set('offg', value=offg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternative combined model for scipy.optimize.minimize\n",
    "combined_p = FitParameters(combined, independent = 't')\n",
    "combined_p.set('tr', min=0, max=MAX_tr, value=tr_0)\n",
    "combined_p.set('tg', min=0, max=MAX_tg, value=tg_0)\n",
    "combined_p.set('m_ktl', min=MIN_m_ktl, max=MAX_m_ktl, value=m_ktl_0)\n",
    "combined_p.set('kmr', min=0, max=MAX_kmr, value=kmr_0)\n",
    "combined_p.set('kmg', min=0, max=MAX_kmg, value=kmg_0)\n",
    "combined_p.set('betr', min=0, max=MAX_betr, value=betr_0)\n",
    "combined_p.set('betg', min=0, max=MAX_betg, value=betg_0)\n",
    "combined_p.set('deltr', min=0, max=MAX_deltr, value=deltr_0)\n",
    "combined_p.set('deltg', min=0, max=MAX_deltg, value=deltg_0)\n",
    "combined_p.set('offr', value=offr_0)\n",
    "combined_p.set('offg', value=offg_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian\n",
    "To increase the efficiency of fitting, the Jacobian matrix of the objective function is provided to the optimization routine.\n",
    "If the objective function is a typical negative log-likelihood function with normal distribution of residuals\n",
    "$$\n",
    " L(\\theta) = \\sum_{t\\in T} \\frac{1}{2\\sigma_t^2} \\big(D_t - f(t\\mid\\theta)\\big)^2 \\text{,}\n",
    "$$\n",
    "where $D_t$ is the measured data at time $t$ and $f(t\\mid\\theta)$ is the value of the model function at time $t$ with parameters $\\theta$, the Jacobian is:\n",
    "$$\\begin{align}\n",
    "\\nabla L(\\theta) &= \\nabla \\sum_{t\\in T} \\frac{1}{2\\sigma_t^2} \\big(D_t - f\\left(t\\,\\middle|\\,\\theta\\right)\\big)^2 \\\\\n",
    "&= \\sum_{t\\in T} \\nabla \\frac{1}{2\\sigma_t^2} \\big( D_t - f\\left(t\\,\\middle|\\,\\theta\\right) \\big)^2 \\\\\n",
    "&= \\sum_{t\\in T} \\frac{1}{\\sigma_t^2} \\big( D_t - f\\left(t\\,\\middle|\\,\\theta\\right) \\big) \\nabla\\big( D_t - f\\left(t\\,\\middle|\\,\\theta\\right) \\big) \\\\\n",
    "&= \\sum_{t\\in T} \\frac{1}{\\sigma_t^2} \\big( D_t - f\\left(t\\,\\middle|\\,\\theta\\right) \\big)\\big(\\nabla D_t - \\nabla  f\\left(t\\,\\middle|\\,\\theta\\right)\\big) \\\\\n",
    "&= -\\sum_{t\\in T} \\frac{1}{\\sigma_t^2} \\big(D_t - f\\left(t\\,\\middle|\\,\\theta\\right)\\big) \\nabla f\\left(t\\,\\middle|\\,\\theta\\right) \\\\\n",
    "\\end{align}$$\n",
    "We see that for calculating the Jacobian of the objective function we need the Jacobian of the model function.\n",
    "\n",
    "We use the general expression model function\n",
    "$$\n",
    "f\\left(t \\,\\middle|\\, t_0, m, k, \\beta, \\delta, a\\right) = a + m \\left(\\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)} + \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{k + \\beta - \\delta} - \\frac{\\mathrm{e}^{- \\beta \\left(t - t_{0}\\right)}}{\\beta - \\delta}\\right) \\text{,}\n",
    "$$\n",
    "where $t_0$ is the mRNA expression onset time, $m$ is the product of initial mRNA amount and translation rate, $k$ is the maturation rate, $\\beta$ is the protein degradation rate, $\\delta$ is the mRNA degradation rate, and $a$ is a vertical offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian $\\nabla f\\left(t \\,\\middle|\\, t_0, m, k, \\beta, \\delta, a\\right)$ of the general expression model function is the vector of the derivatives with respect to the various parameters:\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial f}{\\partial t_0} &= m \\left(\\frac{k \\delta \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)} - \\frac{\\beta \\mathrm{e}^{- \\beta \\left(t - t_{0}\\right)}}{\\beta - \\delta} + \\frac{\\left(k + \\beta\\right) \\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{k + \\beta - \\delta}\\right)\\\\\n",
    "\\frac{\\partial f}{\\partial m} &= \\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)} + \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{k + \\beta - \\delta} - \\frac{\\mathrm{e}^{- \\beta \\left(t - t_{0}\\right)}}{\\beta - \\delta}\\\\\n",
    "\\frac{\\partial f}{\\partial k} &= m \\left(- \\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)^{2}} + \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{k + \\beta - \\delta} \\left(- t + t_{0}\\right) - \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{\\left(k + \\beta - \\delta\\right)^{2}} + \\frac{\\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)}\\right)\\\\\n",
    "\\frac{\\partial f}{\\partial \\beta} &= m \\left(- \\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)^{2}} - \\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right)^{2} \\left(k + \\beta - \\delta\\right)} + \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{k + \\beta - \\delta} \\left(- t + t_{0}\\right) - \\frac{\\mathrm{e}^{- \\beta \\left(t - t_{0}\\right)}}{\\beta - \\delta} \\left(- t + t_{0}\\right) - \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{\\left(k + \\beta - \\delta\\right)^{2}} + \\frac{\\mathrm{e}^{- \\beta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right)^{2}}\\right)\\\\\n",
    "\\frac{\\partial f}{\\partial \\delta} &= m \\left(\\frac{k \\left(- t + t_{0}\\right) \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)} + \\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right) \\left(k + \\beta - \\delta\\right)^{2}} + \\frac{k \\mathrm{e}^{- \\delta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right)^{2} \\left(k + \\beta - \\delta\\right)} + \\frac{\\mathrm{e}^{\\left(- k - \\beta\\right) \\left(t - t_{0}\\right)}}{\\left(k + \\beta - \\delta\\right)^{2}} - \\frac{\\mathrm{e}^{- \\beta \\left(t - t_{0}\\right)}}{\\left(\\beta - \\delta\\right)^{2}}\\right)\\\\\n",
    "\\frac{\\partial f}{\\partial a} &= 1\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def general_jacobian(**params):\n",
    "    \n",
    "    a = params['offset']\n",
    "    t0 = params['t0']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data and prepare result list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate kernel density estimation of parameter distributions\n",
    "def parameter_KDE(par_tab):\n",
    "    \"\"\"Returns a kernel density estimation of the parameter values for plotting\"\"\"\n",
    "    dens_res = 200\n",
    "    bw_div = 15\n",
    "\n",
    "    par_dist = {}\n",
    "\n",
    "    for par_name in par_tab.columns:\n",
    "        # Get parameter values\n",
    "        par_vals = par_tab.loc[:,par_name].values\n",
    "        par_vals = par_vals.reshape((par_vals.size, 1))\n",
    "\n",
    "        # Test parameter values for validity\n",
    "        if np.any(np.logical_not(np.isfinite(par_vals))):\n",
    "            print(\"Warning: invalid values encountered for “{}”\".format(par_name))\n",
    "            par_vals = par_vals(np.isfinite(par_vals))\n",
    "            if par_vals.size > 0:\n",
    "                # Calculate distribution of valid entries\n",
    "                par_vals = par_vals.reshape((par_vals.size, 1))\n",
    "            else:\n",
    "                # No valid entries found; cancel distribution calculation\n",
    "                par_dist[par_name] = {'val': [], 'prob': []}\n",
    "                continue\n",
    "\n",
    "        # Get parameter extrema and bandwidth\n",
    "        par_min = np.min(par_vals)\n",
    "        par_max = np.max(par_vals)\n",
    "        bw = (par_max - par_min) / bw_div\n",
    "\n",
    "        # Get kernel density estimation of parameter values\n",
    "        kde = KernelDensity(kernel='epanechnikov', bandwidth=bw).fit(par_vals)\n",
    "        par_x = np.linspace(par_min, par_max, dens_res).reshape((dens_res, 1))\n",
    "        par_dens = np.exp(kde.score_samples(par_x))\n",
    "\n",
    "        # Adjust values for nicer plotting (KDE >= 0, edges == 0)\n",
    "        #par_dens[par_dens < 0] = 0\n",
    "        if par_dens[0] != 0:\n",
    "            par_dens = np.insert(par_dens, 0, 0)\n",
    "            par_x = np.insert(par_x, 0, par_min)\n",
    "        if par_dens[-1] != 0:\n",
    "            par_dens = np.append(par_dens, 0)\n",
    "            par_x = np.append(par_x, par_max)\n",
    "\n",
    "        # Insert KDE into dict\n",
    "        par_dist[par_name] = {'val': par_x.flatten(), 'prob': par_dens.flatten()}\n",
    "    return par_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_kde(ax, dist, label, clr_face='b', clr_edge='k', mark=None):\n",
    "    \"\"\"Plots the current parameter value in relation to the distribution\n",
    "    in the whole dataset.\"\"\"\n",
    "    ax.fill_betweenx(dist['val'], dist['prob'], color=clr_face)\n",
    "    if mark != None:\n",
    "        ax.axhline(y=mark, color=clr_edge)\n",
    "    ax.set_xticks([])\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    for s in [ax.spines[pos] for pos in ['bottom', 'right', 'top']]:\n",
    "        s.set_visible(False)\n",
    "    ax.set_title(label)\n",
    "    #ax.get_yaxis().set_major_formatter(StrMethodFormatter('{x:.2g}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data loading\n",
    "\n",
    "# Define available files\n",
    "datafiles = [\n",
    "    {\n",
    "        \"sample\": \"A549\",\n",
    "        \"condition\": \"control\",\n",
    "        \"measurement\": \"Test\",\n",
    "        \"file\": \"data/A549_control_test.xlsx\"\n",
    "    },\n",
    "    {\n",
    "        \"sample\": \"A549\",\n",
    "        \"condition\": \"siRNA\",\n",
    "        \"measurement\": \"2016-01-09_seq3\",\n",
    "        \"file\": \"data/2016-01-09_seq3_A549_siRNA_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"A549\",\n",
    "        \"condition\": \"control\",\n",
    "        \"measurement\": \"2016-01-09_seq5\",\n",
    "        \"file\": \"data/2016-01-09_seq5_A549_Control_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"A549\",\n",
    "        \"condition\": \"siRNA\",\n",
    "        \"measurement\": \"2016-12-20_seq3\",\n",
    "        \"file\": \"data/2016-12-20_seq3_A549_siRNA_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"A549\",\n",
    "        \"condition\": \"control\",\n",
    "        \"measurement\": \"2016-12-20_seq4\",\n",
    "        \"file\": \"data/2016-12-20_seq4_A549_control_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"siRNA\",\n",
    "        \"measurement\": \"2017-05-26_seq10\",\n",
    "        \"file\": \"data/2017-05-26_seq10_Huh7_siRNA_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"siRNA\",\n",
    "        \"measurement\": \"2017-05-26_seq11\",\n",
    "        \"file\": \"data/2017-05-26_seq11_Huh7_siRNA_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"control\",\n",
    "        \"measurement\": \"2017-05-26_seq6\",\n",
    "        \"file\": \"data/2017-05-26_seq6_Huh7_control_#molecules.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"control\",\n",
    "        \"measurement\": \"2017-05-26_seq7\",\n",
    "        \"file\": \"data/2017-05-26_seq7_Huh7_control_#molecules.xlsx\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# By default, mark all files for loading\n",
    "load_idcs = range(len(datafiles))\n",
    "\n",
    "# Define function for loading data\n",
    "def load_data_from_files():\n",
    "    \"\"\"Loads data from specified files into `D`.\n",
    "    Requires `load_idcs` to hold a list of indices to `datafiles`.\"\"\"\n",
    "    global D\n",
    "    D = []\n",
    "    for i in load_idcs:\n",
    "        # Show message\n",
    "        print(\"Loading file: {}\".format(datafiles[i][\"file\"]))\n",
    "\n",
    "        # Read sheets from excel file\n",
    "        X = pd.read_excel(datafiles[i]['file'], dtype=np.float64, sheetname=[\n",
    "            '#RFP', '#GFP_corrected', '#RFP_error', '#GFP_error'])\n",
    "\n",
    "        # Write data into easy-to-access structure\n",
    "        d = {}\n",
    "        d['sample'] = datafiles[i]['sample']\n",
    "        d['condition'] = datafiles[i]['condition']\n",
    "        d['measurement'] = datafiles[i]['measurement']\n",
    "        d['file'] = datafiles[i]['file']\n",
    "        d['t'] = X['#RFP'].values[:,0].flatten()\n",
    "        #d['rfp'] = X['RFP'].values[:,1:]\n",
    "        #d['gfp'] = X['GFP_corrected'].values[:,1:]\n",
    "        d['rfp'] = X['#RFP'].values[:,1:]\n",
    "        d['gfp'] = X['#GFP_corrected'].values[:,1:]\n",
    "        d['rfp_error'] = X['#RFP_error'].values[:,1:]\n",
    "        d['gfp_error'] = X['#GFP_error'].values[:,1:]\n",
    "        D.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataLabel(i, filename=False):\n",
    "    \"\"\"Returns a nicely formatted name for the `i`-th element of `D`.\n",
    "    Set `filename=True` for a filename-friendly output.\"\"\"\n",
    "    if filename:\n",
    "        return \"{0[measurement]}_{0[sample]}_{0[condition]}\".format(D[i])\n",
    "    return \"{0[sample]}: {0[condition]} [{0[measurement]}]\".format(D[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in data from excel sheets\n",
    "\n",
    "# Prompt user for files to load\n",
    "lbl = wdg.Label('Select the files to load:')\n",
    "lbl.layout.width = 'initial'\n",
    "entries = []\n",
    "for f in datafiles:\n",
    "    entries.append(\"{} {}: {}\".format(\n",
    "        f['sample'], f['condition'], f['file']))\n",
    "sel_entry = wdg.SelectMultiple(options=entries, rows=len(entries))\n",
    "sel_entry.layout.width = 'initial'\n",
    "bload = wdg.Button(description='Load')\n",
    "bselall = wdg.Button(description='Select all')\n",
    "bselnone = wdg.Button(description='Select none')\n",
    "\n",
    "# Define callbacks\n",
    "def sel_all_files(_):\n",
    "    sel_entry.value = entries\n",
    "def sel_no_files(_):\n",
    "    sel_entry.value = ()\n",
    "def load_button_clicked(_):\n",
    "    global load_idcs\n",
    "    load_idcs = [entries.index(r) for r in sel_entry.value]\n",
    "    vb.close()\n",
    "    load_data_from_files()\n",
    "bselall.on_click(sel_all_files)\n",
    "bselnone.on_click(sel_no_files)\n",
    "bload.on_click(load_button_clicked)\n",
    "\n",
    "# Finally, show the widgets\n",
    "vb = wdg.VBox((lbl, sel_entry, wdg.HBox((bload,bselall,bselnone))))\n",
    "IPython.display.display(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provide output tables\n",
    "\n",
    "# Initialize result dictionary\n",
    "R = []\n",
    "\n",
    "# Get a list of fit parameters\n",
    "par_names = green_p.names().tolist()\n",
    "par_names.extend(p for p in red_p.names() if p not in par_names)\n",
    "par_names.sort()\n",
    "\n",
    "# Iteratively populate the result dictionary\n",
    "for k in range(len(D)):\n",
    "    R.insert(k, {})\n",
    "    nTraces = np.shape(D[k]['gfp'])[1]\n",
    "    nTimes = np.shape(D[k]['gfp'])[0]\n",
    "    tpl_traces = np.empty((nTimes, nTraces))\n",
    "    tpl_traces.fill(np.NaN)\n",
    "\n",
    "    R[k]['green'] = {}\n",
    "    R[k]['green']['params'] = pd.DataFrame(index=np.arange(nTraces), columns=green_p.names(), dtype='float64')\n",
    "    R[k]['green']['fit'] = np.copy(tpl_traces)\n",
    "\n",
    "    R[k]['red'] = {}\n",
    "    R[k]['red']['params'] = pd.DataFrame(index=np.arange(nTraces), columns=red_p.names(), dtype='float64')\n",
    "    R[k]['red']['fit'] = np.copy(tpl_traces)\n",
    "\n",
    "    R[k]['combined'] = {}\n",
    "    R[k]['combined']['params'] = pd.DataFrame(index=np.arange(nTraces), columns=combined_p.names(), dtype='float64')\n",
    "    #R[k]['combined']['fit'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle or load fitting results\n",
    "Pickling is only reasonable if the result list `R` has already been populated by fitting (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle fit results for future sessions\n",
    "outfile = getTimeStamp() + '_fit_results.pickled'\n",
    "with open(outfile, 'wb') as f:\n",
    "    pickle.dump(R, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pickled results (requires file suffix “.pickled”)\n",
    "pickfiles = [f for f in os.listdir() if f.lower().endswith('.pickled')]\n",
    "pickfiles.sort(reverse=True)\n",
    "\n",
    "lbl = wdg.Label('Select the file to load:')\n",
    "lbl.layout.width = 'initial'\n",
    "rad = wdg.RadioButtons(options=pickfiles)\n",
    "but = wdg.Button(description='Load')\n",
    "vb = wdg.VBox([lbl, rad, but])\n",
    "IPython.display.display(vb)\n",
    "\n",
    "def clicked_on_but(b):\n",
    "    global R\n",
    "    with open(rad.value, 'rb') as f:\n",
    "        R = pickle.load(f)\n",
    "    print('Loaded: ' + rad.value)\n",
    "    vb.close()\n",
    "but.on_click(clicked_on_but)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and plot separate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotSeparate(ds, tr, pdf=None, par_kde=None):\n",
    "    \"\"\"Fits and plots the data, treating RFP and GFP separately.\n",
    "\n",
    "    Keyword arguments:\n",
    "    ds -- the dictionary key of the dataset\n",
    "    tr -- the index of the trace in the dataset to be processed\n",
    "    pdf -- a PdfPages object to which the figure is written if it is not None\n",
    "    par_kde -- if containing dict of values of parameter distributions, plot distributions\n",
    "    \"\"\"\n",
    "\n",
    "    # Plot fit results\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if par_kde != None:\n",
    "        fig.set_figwidth(1.6 * fig.get_figwidth())\n",
    "\n",
    "        pn_red = ['m_ktl', 'tr', 'kmr', 'betr', 'deltr', 'offr']\n",
    "        pn_green = ['m_ktl', 'tg', 'kmg', 'betg', 'deltg', 'offg']\n",
    "\n",
    "        grid = (2, max(len(pn_red), len(pn_green)))\n",
    "        gs = GridSpec(grid[0], grid[1])\n",
    "\n",
    "        # Plot green parameters\n",
    "        for pi, label in enumerate(pn_green):\n",
    "            ax = plt.subplot(gs.new_subplotspec((0, pi)))\n",
    "            data = par_kde['green'][label]\n",
    "            clr_face = '#00ff0055'\n",
    "            clr_edge = '#009900ff'\n",
    "            curr_val = R[ds]['green']['params'].loc[tr,label]\n",
    "            plot_kde(ax, data, label, clr_face, clr_edge, curr_val)\n",
    "\n",
    "        # Plot red parameters\n",
    "        for pi, label in enumerate(pn_red):\n",
    "            ax = plt.subplot(gs.new_subplotspec((1, pi)))\n",
    "            data = par_kde['red'][label]\n",
    "            clr_face = '#ff000055'\n",
    "            clr_edge = '#990000ff'\n",
    "            curr_val = R[ds]['red']['params'].loc[tr,label]\n",
    "            plot_kde(ax, data, label, clr_face, clr_edge, curr_val)\n",
    "\n",
    "        # Adjust subplot layout\n",
    "        gs.tight_layout(fig, pad=0, rect=(0.5, 0, 1, 1))\n",
    "\n",
    "        # Create axes for fit\n",
    "        gs_fit = GridSpec(1, 1)\n",
    "        ax = fig.add_subplot(gs_fit[0])\n",
    "        gs_fit.tight_layout(fig, pad=0, rect=(0, 0, 0.5, 1))\n",
    "\n",
    "    else:\n",
    "        ax = fig.gca()\n",
    "\n",
    "    p_tr = ax.axvline(R[ds]['red']['params']['tr'][tr], label='RFP onset',\n",
    "                       color='#ff0000', linewidth=.5, linestyle='--')\n",
    "    p_tg = ax.axvline(R[ds]['green']['params']['tg'][tr], label='GFP onset',\n",
    "                      color='#00ff00', linewidth=.5, linestyle='--')\n",
    "    p_fr, = ax.plot(D[ds]['t'], R[ds]['red']['fit'][:,tr], '-', label='RFP (fit)', color='#ff0000', linewidth=1)\n",
    "    p_fg, = ax.plot(D[ds]['t'], R[ds]['green']['fit'][:,tr], '-', label='GFP (fit)', color='#00ff00', linewidth=1)\n",
    "    p_dr, = ax.plot(D[ds]['t'], D[ds]['rfp'][:,tr], '-', label='RFP (measured)', color='#990000', linewidth=.5)\n",
    "    p_dg, = ax.plot(D[ds]['t'], D[ds]['gfp'][:,tr], '-', label='GFP (measured)', color='#009900', linewidth=.5)\n",
    "\n",
    "    # Format plot\n",
    "    ax.set_xlabel('Time [h]')\n",
    "    ax.set_ylabel('Fluorescence intensity [a.u.]')\n",
    "    ax.set_title('{} #{:03d}\\n(separate fit)'.format(getDataLabel(ds), tr))\n",
    "    ax.legend(handles=[p_dg, p_fg, p_tg, p_dr, p_fr, p_tr])\n",
    "\n",
    "    # Write figure to pdf\n",
    "    if pdf != None:\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "\n",
    "    # Show and close figure\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit traces separately\n",
    "for ds in range(len(D)):\n",
    "    nTraces = np.shape(D[ds]['rfp'])[1]\n",
    "\n",
    "    for tr in range(nTraces):\n",
    "        print('Fitting „{}“ #{:03d}/{:03d} …'.format(getDataLabel(ds), tr, nTraces))\n",
    "        \n",
    "        # Prepare data\n",
    "        data_red = D[ds]['rfp'][:,tr].flatten()\n",
    "        data_green = D[ds]['gfp'][:,tr].flatten()\n",
    "\n",
    "        wght_red = D[ds]['rfp_error'][:,tr]**2\n",
    "        wght_green = D[ds]['gfp_error'][:,tr]**2\n",
    "        \n",
    "        # Adjust parameter properties for onset time and offset\n",
    "        red_p.set('tr', max=D[ds]['t'][data_red.argmax()])\n",
    "        red_p.set('offr',\n",
    "                       min=data_red[:10].min(),\n",
    "                       max=data_red[:10].max(),\n",
    "                       value=np.median(data_red[:10]))\n",
    "        green_p.set('tg', max=D[ds]['t'][data_green.argmax()])\n",
    "        green_p.set('offg',\n",
    "                       min=data_green[:10].min(),\n",
    "                       max=data_green[:10].max(),\n",
    "                       value=np.median(data_green[:10]))\n",
    "\n",
    "        # Objective function (closure)\n",
    "        i_obj = 0\n",
    "        isChisqRedNan = False\n",
    "        def objective_fcn(params):\n",
    "            \"\"\"Objective function for separate model\"\"\"\n",
    "\n",
    "            # Compute chisquare\n",
    "            cur_val = red_p.eval(params, t=D[ds]['t'])\n",
    "            chisq = np.sum(.5 * (data_red - cur_val)**2 / wght_red)\n",
    "\n",
    "            # DEBUG\n",
    "            global i_obj, isChisqRedNan\n",
    "            #print(\"Trace {:03d}, i={:03d}: chisq={}\".format(tr, i_obj, chisq))\n",
    "            #for p,v in zip(red_p.names(), params):\n",
    "            #    print(\"\\t{:>10s} = {}\".format(p, v))\n",
    "\n",
    "            # Print model values at first iteration with NaN chisquare\n",
    "            #if np.isnan(chisq) and not isChisqRedNan:\n",
    "            #    print(cur_val)\n",
    "            #    isChisqNan = True\n",
    "            i_obj += 1\n",
    "\n",
    "            return chisq\n",
    "\n",
    "        # Fit the data\n",
    "        result = sc.optimize.minimize(objective_fcn,\n",
    "                                      red_p.initial(),\n",
    "                                      method='TNC',# one of: 'SLSQP' 'TNC' 'L-BFGS-B'\n",
    "                                      bounds=red_p.bounds(),\n",
    "                                      options={'disp':True,\n",
    "                                               'maxiter': 10000}\n",
    "                                     )\n",
    "\n",
    "        # Print result\n",
    "        print(\"\\tRed success {}: {}\".format(result.success, result.message))\n",
    "\n",
    "        # Save results to R\n",
    "        R[ds]['red']['params'].iloc[tr] = result.x\n",
    "        best_fit = red(D[ds]['t'], *result.x)\n",
    "        R[ds]['red']['fit'][:,tr] = best_fit\n",
    "\n",
    "        # Fit green data\n",
    "        i_obj = 0\n",
    "        isChisqGreenNan = False\n",
    "        def objective_fcn(params):\n",
    "            \"\"\"Objective function for green model\"\"\"\n",
    "\n",
    "            # Computer chisquare\n",
    "            cur_val = green_p.eval(params, t=D[ds]['t'])\n",
    "            chisq = np.sum(.5 * (data_green - cur_val)**2 / wght_green)\n",
    "\n",
    "            # DEBUG\n",
    "            global i_obj, isChisqGreenNan\n",
    "            #print(\"Trace {:03d}, i={:03d}: chisq={}\".format(tr, i_obj, chisq))\n",
    "            #for p,v in zip(green_p.names(), params):\n",
    "            #    print(\"\\t{:>10s} = {}\".format(p, v))\n",
    "\n",
    "            # Print model values at first iteration with NaN chisquare\n",
    "            if np.isnan(chisq) and not isChisqGreenNan:\n",
    "            #    print(cur_val)\n",
    "                isChisqNan = True\n",
    "            i_obj += 1\n",
    "\n",
    "            return chisq\n",
    "\n",
    "        result = sc.optimize.minimize(objective_fcn,\n",
    "                                      green_p.initial(),\n",
    "                                      method='TNC',\n",
    "                                      bounds=green_p.bounds(),\n",
    "                                      options={'disp': True,\n",
    "                                               'maxiter': 10000})\n",
    "        print(\"\\tGreen success {}: {}\".format(result.success, result.message))\n",
    "\n",
    "        R[ds]['green']['params'].iloc[tr] = result.x\n",
    "        best_fit = green(D[ds]['t'], *result.x)\n",
    "        R[ds]['green']['fit'][:,tr] = best_fit\n",
    "\n",
    "        # DEBUG\n",
    "        #if tr >= 2:\n",
    "        #    print(\"Breaking loop for debugging purposes\")\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot results of separate fit\n",
    "ts = getTimeStamp()\n",
    "\n",
    "for ds in range(len(D)):\n",
    "    par_kde = {}\n",
    "    for t in ('red', 'green'):\n",
    "        par_kde[t] = parameter_KDE(R[ds][t]['params'])\n",
    "    pdffile = os.path.join(getOutpath(), '{}_separate_{}.pdf'.format(ts, getDataLabel(ds, True)))\n",
    "    with PdfPages(pdffile) as pdf:\n",
    "        for tr in range(np.shape(D[ds]['rfp'])[1]):\n",
    "            plotSeparate(ds, tr, pdf, par_kde)\n",
    "\n",
    "            # DEBUG\n",
    "            #if tr >= 2:\n",
    "            #    print(\"Break loop\")\n",
    "            #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and plot combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotCombined(ds, tr, pdf=None, par_kde=None):\n",
    "    \"\"\"Fits and plots the data, treating RFP and GFP together.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    ds -- the dictionary key of the dataset\n",
    "    tr -- the index of the trace in the dataset to be processed\n",
    "    pdf -- a PdfPages object to which the figure is written if it is not None\n",
    "    par_kde -- if containing dict of values of parameter distributions, plot distributions\n",
    "    \"\"\"\n",
    "\n",
    "    # Plot fit results\n",
    "    fig = plt.figure()\n",
    "    #fig.set_tight_layout(False)\n",
    "\n",
    "    if par_kde != None:\n",
    "        fig.set_figwidth(1.6 * fig.get_figwidth())\n",
    "\n",
    "        #pn_both = ['m', 'ktl']\n",
    "        pn_both = ['m_ktl']\n",
    "        pn_red = ['tr', 'kmr', 'betr', 'deltr', 'offr']\n",
    "        pn_green = ['tg', 'kmg', 'betg', 'deltg', 'offg']\n",
    "\n",
    "        # Plot combined parameters\n",
    "        grid = (2, 1+max(len(pn_red), len(pn_green)))\n",
    "        gs = GridSpec(grid[0], grid[1])\n",
    "\n",
    "        #for pi, label in enumerate(pn_both):\n",
    "        pi = 0\n",
    "        label = pn_both[pi]\n",
    "        ax = plt.subplot(gs.new_subplotspec((pi, 0), rowspan=2))\n",
    "        data = par_kde['combined'][label]\n",
    "        clr_face = '#0000ff55'\n",
    "        clr_edge = '#000099ff'\n",
    "        curr_val = R[ds]['combined']['params'].loc[tr,label]\n",
    "        plot_kde(ax, data, label, clr_face, clr_edge, curr_val)\n",
    "\n",
    "        # Plot green parameters\n",
    "        for pi, label in enumerate(pn_green):\n",
    "            ax = plt.subplot(gs.new_subplotspec((0, pi+1)))\n",
    "            data = par_kde['combined'][label]\n",
    "            clr_face = '#00ff0055'\n",
    "            clr_edge = '#009900ff'\n",
    "            curr_val = R[ds]['combined']['params'].loc[tr,label]\n",
    "            plot_kde(ax, data, label, clr_face, clr_edge, curr_val)\n",
    "\n",
    "        # Plot red parameters\n",
    "        for pi, label in enumerate(pn_red):\n",
    "            ax = plt.subplot(gs.new_subplotspec((1, pi+1)))\n",
    "            data = par_kde['combined'][label]\n",
    "            clr_face = '#ff000055'\n",
    "            clr_edge = '#990000ff'\n",
    "            curr_val = R[ds]['combined']['params'].loc[tr,label]\n",
    "            plot_kde(ax, data, label, clr_face, clr_edge, curr_val)\n",
    "\n",
    "        # Adjust subplot layout\n",
    "        gs.tight_layout(fig, pad=0, rect=(0.5, 0, 1, 1))\n",
    "\n",
    "        # Create axes for fit\n",
    "        gs_fit = GridSpec(1, 1)\n",
    "        ax = fig.add_subplot(gs_fit[0])\n",
    "        gs_fit.tight_layout(fig, pad=0, rect=(0, 0, 0.5, 1))\n",
    "\n",
    "    else:\n",
    "        ax = fig.gca()\n",
    "\n",
    "    #wr = np.sqrt(D[ds]['rfp'][:,tr])\n",
    "    #ax.fill_between(D[ds]['t'], D[ds]['rfp'][:,tr]-wr, D[ds]['rfp'][:,tr]+wr, color='#ff000033')\n",
    "    #wg = np.sqrt(D[ds]['gfp'][:,tr])\n",
    "    #ax.fill_between(D[ds]['t'], D[ds]['gfp'][:,tr]-wg, D[ds]['gfp'][:,tr]+wg, color='#00ff0033')\n",
    "\n",
    "    p_tr = ax.axvline(R[ds]['combined']['params']['tr'][tr], label='RFP onset',\n",
    "                       color='#ff0000', linewidth=.5, linestyle='--')\n",
    "    p_tg = ax.axvline(R[ds]['combined']['params']['tg'][tr], label='GFP onset',\n",
    "                      color='#00ff00', linewidth=.5, linestyle='--')\n",
    "    p_fr, = ax.plot(D[ds]['t'], R[ds]['combined']['fit']['red'][tr], '-', label='RFP (fit)', color='#ff0000', linewidth=1)\n",
    "    p_fg, = ax.plot(D[ds]['t'], R[ds]['combined']['fit']['green'][tr], '-', label='GFP (fit)', color='#00ff00', linewidth=1)\n",
    "    p_dr, = ax.plot(D[ds]['t'], D[ds]['rfp'][:,tr], '-', label='RFP (measured)', color='#990000', linewidth=.5)\n",
    "    p_dg, = ax.plot(D[ds]['t'], D[ds]['gfp'][:,tr], '-', label='GFP (measured)', color='#009900', linewidth=.5)\n",
    "\n",
    "    # Format plot\n",
    "    ax.set_xlabel('Time [h]')\n",
    "    ax.set_ylabel('Fluorescence intensity [a.u.]')\n",
    "    ax.set_title('{} {} [{}] #{:03d}\\n(combined fit)'.format(\n",
    "        D[ds]['sample'], D[ds]['condition'], D[ds]['measurement'], tr))\n",
    "    ax.legend(handles=[p_dg, p_fg, p_tg, p_dr, p_fr, p_tr])\n",
    "\n",
    "    # Write figure to pdf\n",
    "    if pdf != None:\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "\n",
    "    # Show and close figure\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit combined model\n",
    "for ds in range(len(D)):\n",
    "    R[ds]['combined']['fit'] = {'red': [], 'green': []}\n",
    "    nTraces = np.shape(D[ds]['rfp'])[1]\n",
    "\n",
    "    for tr in range(nTraces):\n",
    "        print('Fitting „{}“ #{:03d}/{:03d}. '.format(getDataLabel(ds), tr, nTraces))#, end='')\n",
    "\n",
    "        # Get the data for fitting\n",
    "        data = np.stack([D[ds]['rfp'][:,tr], D[ds]['gfp'][:,tr]], axis=1)\n",
    "        \n",
    "        # Adjust parameter properties for onset time and offset\n",
    "        combined_p.set('tr', max=D[ds]['t'][data[:,0].argmax()])\n",
    "        combined_p.set('offr',\n",
    "                       min=data[:10,0].min(),\n",
    "                       max=data[:10,0].max(),\n",
    "                       value=np.median(data[:10,0]))\n",
    "        combined_p.set('tg', max=D[ds]['t'][data[:,1].argmax()])\n",
    "        combined_p.set('offg',\n",
    "                       min=data[:10,1].min(),\n",
    "                       max=data[:10,1].max(),\n",
    "                       value=np.median(data[:10,1]))\n",
    "\n",
    "        # Get amplitude correction\n",
    "        amp_red = data[:,0].max() - data[:,0].min()\n",
    "        amp_green = data[:,1].max() - data[:,1].min()\n",
    "        amp_correct = amp_red - amp_green\n",
    "\n",
    "        # Fit the data\n",
    "        wght = np.stack([D[ds]['rfp_error'][:,tr], D[ds]['gfp_error'][:,tr]], axis=1)**2\n",
    "\n",
    "        # Set up objective function (as closure)\n",
    "        #i_obj = 0\n",
    "        #isChisqNan = False\n",
    "        def objective_fcn(params):\n",
    "            \"\"\"Objective function for combined model\"\"\"\n",
    "\n",
    "            # Compute chisquare\n",
    "            cur_val = combined_p.eval(params, t=D[ds]['t'])\n",
    "            chisq = np.sum(.5 * (data - cur_val)**2 / wght)\n",
    "\n",
    "            # DEBUG\n",
    "            #global i_obj, isChisqNan\n",
    "            #print(\"Trace {:03d}, i={:03d}: chisq={}\".format(tr, i_obj, chisq))\n",
    "            #for p,v in zip(combined_p.names(), params):\n",
    "            #    print(\"\\t{:>10s} = {}\".format(p, v))\n",
    "\n",
    "            # Print model values at first iteration with NaN chisquare\n",
    "            #if np.isnan(chisq) and not isChisqNan:\n",
    "            #    print(cur_val)\n",
    "            #    isChisqNan = True\n",
    "            #i_obj += 1\n",
    "\n",
    "            return chisq\n",
    "        result = sc.optimize.minimize(objective_fcn,\n",
    "                                      combined_p.initial(),\n",
    "                                      method='TNC',#'L-BFGS-B','TNC'\n",
    "                                      bounds=combined_p.bounds(),\n",
    "                                      options={'disp': True,\n",
    "                                               'maxiter': 10000})\n",
    "\n",
    "        # Save results to R\n",
    "        R[ds]['combined']['params'].iloc[tr] = result.x\n",
    "        best_fit = combined(D[ds]['t'], *result.x)\n",
    "        R[ds]['combined']['fit']['red'].insert(tr, best_fit[:,0])\n",
    "        R[ds]['combined']['fit']['green'].insert(tr, best_fit[:,1])\n",
    "\n",
    "        # Print result\n",
    "        print(\"\\tSuccess {}: {}\".format(result.success, result.message))\n",
    "\n",
    "        # DEBUG\n",
    "        #if tr >= 40:\n",
    "        #    print(\"Breaking loop for debugging purposes\")\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot results of combined fit\n",
    "ts = getTimeStamp()\n",
    "for ds in range(len(D)):\n",
    "    par_kde = {}\n",
    "    for t in ('combined',):\n",
    "        par_kde[t] = parameter_KDE(R[ds][t]['params'])\n",
    "    pdffile = os.path.join(getOutpath(), '{}_combined_{}.pdf'.format(ts, getDataLabel(ds, True)))\n",
    "    with PdfPages(pdffile) as pdf:\n",
    "        for tr in range(np.shape(D[ds]['rfp'])[1]):\n",
    "            plotCombined(ds, tr, pdf, par_kde=par_kde)\n",
    "            \n",
    "            # DEBUG\n",
    "            #if tr >= 40:\n",
    "            #    print(\"Forcing break\")\n",
    "            #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot violin distributions of the data sets (both separate and combined)\n",
    "pn_both = ('m_ktl',)\n",
    "pn_red = ('tr', 'kmr', 'betr', 'deltr', 'offr')\n",
    "pn_green = ('tg', 'kmg', 'betg', 'deltg', 'offg')\n",
    "\n",
    "grid = (2, len(pn_both)+max(len(pn_red), len(pn_green)))\n",
    "\n",
    "with PdfPages(os.path.join(getOutpath(), '{:s}_parameter_distributions.pdf'.format(getTimeStamp()))) as pdf:\n",
    "    for ds in range(len(D)):\n",
    "\n",
    "        par_kde = {}\n",
    "        fit_types = []\n",
    "\n",
    "        # Check for separate fit\n",
    "        if 'red' in R[ds] and 'green' in R[ds]:\n",
    "            hasSeparate = True\n",
    "            fit_types += ['red', 'green']\n",
    "        else:\n",
    "            hasSeparate = False\n",
    "\n",
    "        # Check for combined fit\n",
    "        par_kde_combined = {}\n",
    "        if 'combined' in R[ds]:\n",
    "            hasCombined = True\n",
    "            fit_types += ['combined']\n",
    "        else:\n",
    "            hasCombined = False\n",
    "\n",
    "        # Calculate parameter distributions\n",
    "        for t in fit_types:\n",
    "            par_kde[t] = parameter_KDE(R[ds][t]['params'])\n",
    "\n",
    "        # Plot parameter distributions\n",
    "        for typeName, hasType in zip(('separate', 'combined'), (hasSeparate, hasCombined)):\n",
    "            if not hasType:\n",
    "                continue\n",
    "\n",
    "            fig = plt.figure()\n",
    "            gs = GridSpec(grid[0], grid[1])\n",
    "\n",
    "            if typeName == 'combined':\n",
    "                # Combined fit; define specific settings\n",
    "                pn_green_temp = pn_green\n",
    "                pn_red_temp = pn_red\n",
    "                offset_both = len(pn_both)\n",
    "                kde_label_green = 'combined'\n",
    "                kde_label_red = 'combined'\n",
    "\n",
    "                # Plot combined parameters\n",
    "                for pi, label in enumerate(pn_both):\n",
    "                    ax = plt.subplot(gs.new_subplotspec((pi, 0), rowspan=2))\n",
    "                    data = par_kde['combined'][label]\n",
    "                    clr_face = '#0000ff55'\n",
    "                    #clr_edge = '#000099ff'\n",
    "                    plot_kde(ax, data, label, clr_face)\n",
    "            else:\n",
    "                # Separate fit; define specific settings\n",
    "                pn_green_temp = pn_both + pn_green\n",
    "                pn_red_temp = pn_both + pn_red\n",
    "                offset_both = 0\n",
    "                kde_label_green = 'green'\n",
    "                kde_label_red = 'red'\n",
    "\n",
    "            # Plot green parameters\n",
    "            for pi, par_label in enumerate(pn_green_temp):\n",
    "                ax = plt.subplot(gs.new_subplotspec((0, pi+offset_both)))\n",
    "                data = par_kde[kde_label_green][par_label]\n",
    "                clr_face = '#00ff0055'\n",
    "                #clr_edge = '#009900ff'\n",
    "                plot_kde(ax, data, par_label, clr_face)\n",
    "\n",
    "            # Plot red parameters\n",
    "            for pi, par_label in enumerate(pn_red_temp):\n",
    "                ax = plt.subplot(gs.new_subplotspec((1, pi+offset_both)))\n",
    "                data = par_kde[kde_label_red][par_label]\n",
    "                clr_face = '#ff000055'\n",
    "                #clr_edge = '#990000ff'\n",
    "                plot_kde(ax, data, par_label, clr_face)\n",
    "\n",
    "            # Show and close figure\n",
    "            fig.suptitle(getDataLabel(ds) + \" (\" + typeName + \" fit)\")\n",
    "            fig.tight_layout(pad=0, rect=(0, 0, 1, .93))\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            plt.show(fig)\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground\n",
    "This section contains code that was/is used for developing ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the parameter distributions for the datasets\n",
    "ds_keys = list(R.keys())\n",
    "ds_keys.sort()\n",
    "params = R[ds_keys[0]]['combined']['params'].columns\n",
    "grid = (len(params), len(ds_keys))\n",
    "i_col = 0\n",
    "\n",
    "pdffile = os.path.join(getOutpath(), '{:s}_parameters.pdf'.format(getTimeStamp()))\n",
    "with PdfPages(pdffile) as pdf:\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(grid[0] * .8 * fig.get_figheight())\n",
    "    fig.set_figwidth(grid[1] * .8 * fig.get_figwidth())\n",
    "\n",
    "    for ds in ds_keys:\n",
    "        i_row = 0\n",
    "        for p in params:\n",
    "            ax = plt.subplot2grid(grid, (i_row, i_col))\n",
    "            ax.hist(R[ds]['combined']['params'][p], bins=100)\n",
    "            if i_row == grid[0] - 1:\n",
    "                ax.set_xlabel('Value [a.u.]')\n",
    "            if i_col == 0:\n",
    "                ax.set_ylabel('Occurrences [#]')\n",
    "            ax.set_title('{:s}: {:s}'.format(ds, p))\n",
    "            i_row += 1\n",
    "        i_col += 1\n",
    "\n",
    "    pdf.savefig(fig)\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot onset time correlations\n",
    "pdffile = os.path.join(getOutpath(), '{:s}_onset_correlations.pdf'.format(getTimeStamp()))\n",
    "with PdfPages(pdffile) as pdf:\n",
    "    for k in R.keys():\n",
    "        fig = plt.figure()\n",
    "        plt.plot([0, 30], [0, 30], 'k-')\n",
    "        plt.plot(R[k]['combined']['params']['tr'], R[k]['combined']['params']['tg'], '.')\n",
    "        plt.xlabel('Onset RFP [h]')\n",
    "        plt.ylabel('Onset GFP [h]')\n",
    "        plt.title(k)\n",
    "        pdf.savefig(fig)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Degradation rate ratio\n",
    "def plotHistograms(maxH):\n",
    "    Rkeys = sorted(R.keys())\n",
    "    for ds in Rkeys:\n",
    "        #deltg = R[ds]['green']['params']['deltg']\n",
    "        #deltr = R[ds]['red']['params']['deltr']\n",
    "        deltg = R[ds]['combined']['params']['deltg']\n",
    "        deltr = R[ds]['combined']['params']['deltr']\n",
    "        quot = deltg / deltr\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.hist(quot, bins=150, range=(0, maxH))\n",
    "        plt.title(ds)\n",
    "        plt.xlabel('$\\delta_\\mathrm{green} / \\delta_\\mathrm{red}$ [a.u.]')\n",
    "        plt.ylabel('Occurrences [#]')\n",
    "        plt.show(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "wdg.interact(plotHistograms, maxH=wdg.IntSlider(\n",
    "    value=100, min=0, max=1000, step=10, description='Histogram maximum', continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit distribution to degradation rate quotient histograms\n",
    "def gamma(x, p=2, b=1, s=10):\n",
    "    return s * b**p * x**(p-1) * np.exp(-b * x) / sc.special.gamma(p)\n",
    "\n",
    "def gamma2(x, p1=1.9, p2=2.1, b1=0.9, b2=1.1, s1=10, s2=10):\n",
    "    return gamma(x, p1, b1, s1) + gamma(x, p2, b2, s2)\n",
    "\n",
    "def weibull(x, lmbd=.2, k=2, s=10):\n",
    "    return s * lmbd * k * (lmbd * x)**(k - 1) * np.exp(- (lmbd * x)**k)\n",
    "\n",
    "def weibull2(x, lmbd1=.15, lmbd2=.25, k1=1.9, k2=2.1, s1=10, s2=10):\n",
    "    return weibull(x, lmbd=lmbd1, k=k1, s=s1) + weibull(x, lmbd=lmbd2, k=k2, s=s2)\n",
    "\n",
    "# Define models\n",
    "model_gamma = lm.Model(gamma)\n",
    "model_gamma.set_param_hint(name='p', min=.01)\n",
    "model_gamma.set_param_hint(name='b', min=.01)\n",
    "model_gamma.set_param_hint(name='s', min=1)\n",
    "\n",
    "model_gamma2 = lm.Model(gamma2)\n",
    "model_gamma2.set_param_hint(name='p1', min=.01)\n",
    "model_gamma2.set_param_hint(name='p2', min=.01)\n",
    "model_gamma2.set_param_hint(name='b1', min=.01)\n",
    "model_gamma2.set_param_hint(name='b2', min=.01)\n",
    "model_gamma2.set_param_hint(name='s1', min=1)\n",
    "model_gamma2.set_param_hint(name='s2', min=1)\n",
    "\n",
    "model_weibull = lm.Model(weibull)\n",
    "model_weibull.set_param_hint(name='lmbd', min=.001)\n",
    "model_weibull.set_param_hint(name='k', min=.001, max=5)\n",
    "model_weibull.set_param_hint(name='s', min=1)\n",
    "\n",
    "model_weibull2 = lm.Model(weibull2)\n",
    "model_weibull2.set_param_hint(name='lmbd1', min=.001)\n",
    "model_weibull2.set_param_hint(name='lmbd2', min=.001)\n",
    "model_weibull2.set_param_hint(name='k1', min=.001, max=5)\n",
    "model_weibull2.set_param_hint(name='k2', min=.001, max=5)\n",
    "model_weibull2.set_param_hint(name='s1', min=1)\n",
    "model_weibull2.set_param_hint(name='s2', min=1)\n",
    "\n",
    "maxH = 40\n",
    "\n",
    "with PdfPages(os.path.join(getOutpath(), '{:s}_degradation_distribution.pdf'.format(getTimeStamp()))) as pdf:\n",
    "    for ds in sorted(R.keys()):\n",
    "        # Calculate degradation rate quotient\n",
    "        deltg = R[ds]['combined']['params']['deltg']\n",
    "        deltr = R[ds]['combined']['params']['deltr']\n",
    "        quot = deltg / deltr\n",
    "\n",
    "        # Create histogram\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        hist_val, hist_edg = ax.hist(quot, bins=70, range=(0, maxH), label='Histogram')[:2]\n",
    "        hist_ctr = (hist_edg[:-1] + hist_edg[1:]) / 2\n",
    "\n",
    "        # Fit models\n",
    "        result_g = model_gamma.fit(hist_val, x=hist_ctr)\n",
    "        result_g2 = model_gamma2.fit(hist_val, x=hist_ctr)\n",
    "        result_w = model_weibull.fit(hist_val, x=hist_ctr)\n",
    "        result_w2 = model_weibull2.fit(hist_val, x=hist_ctr)\n",
    "\n",
    "        # Select models\n",
    "        #print('gamma: {}'.format(result_g.chisqr))\n",
    "        #print('gamma2: {}'.format(result_g2.chisqr))\n",
    "        #print('weibull: {}'.format(result_w.chisqr))\n",
    "        #print('weibull2: {}'.format(result_w2.chisqr))\n",
    "\n",
    "        if result_g2.chisqr < .7 * result_g.chisqr:\n",
    "            res_g = result_g2\n",
    "            name_g = 'gamma2'\n",
    "        else:\n",
    "            res_g = result_g\n",
    "            name_g = 'gamma'\n",
    "\n",
    "        if result_w2.chisqr < .7 * result_w.chisqr:\n",
    "            res_w = result_w2\n",
    "            name_w = 'weibull2'\n",
    "        else:\n",
    "            res_w = result_w\n",
    "            name_w = 'weibull'\n",
    "\n",
    "        # Plot models\n",
    "        x = np.linspace(.1, 5, 100)\n",
    "        ax.plot(hist_ctr, res_g.best_fit, '-', label=name_g, color='orange')\n",
    "        ax.plot(hist_ctr, res_w.best_fit, '-', label=name_w, color='magenta')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('$\\delta_\\mathrm{green} / \\delta_\\mathrm{red}$ [a.u.]')\n",
    "        ax.set_ylabel('Counts [#]')\n",
    "        ax.set_title(ds)\n",
    "\n",
    "        # Print fit reports\n",
    "        rep = res_g.fit_report(show_correl=False) + '\\n' + res_w.fit_report(show_correl=False)\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 1, rep, ha='left', va='top', family='monospace', size=5.5)\n",
    "\n",
    "        # Display, save and close figure\n",
    "        plt.show(fig)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot of degradation rates\n",
    "Rkeys = sorted(R.keys())\n",
    "for ds in Rkeys:\n",
    "    deltg = R[ds]['combined']['params']['deltg']\n",
    "    deltr = R[ds]['combined']['params']['deltr']\n",
    "\n",
    "    fig = plt.figure()\n",
    "    h = plt.plot(deltg, deltr, '.')\n",
    "    plt.title(ds)\n",
    "    plt.xlabel('$\\delta_\\mathrm{green}$ [a.u.]')\n",
    "    plt.ylabel('$\\delta_\\mathrm{red}$ [a.u.]')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
