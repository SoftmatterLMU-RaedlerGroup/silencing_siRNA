{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## siRNA knockdown fixed ##\n",
    "This notebook fits traces with fixed mRNA expression.\n",
    "\n",
    "An amount of mRNA is added to the cells.\n",
    "At a certain time $t=0$, a fixing agent (CHX) is added, and mRNA expression is stopped.\n",
    "Now, an initial amount $G_{u0}$ of pre-mature protein and an initial amount $G_0$ of mature protein is in the cell.\n",
    "\n",
    "After adding the fixing agent, the pre-mature protein can mature with maturation rate $k_m$, and both pre-mature and mature protein can degrade with degradation rate $\\beta$.\n",
    "\n",
    "This system can be described by the following differential equations:\n",
    "$$\\begin{align*}\n",
    "\\frac{\\mathrm{d}G_u}{\\mathrm{d}t} &= -\\beta G_u - k_m G_u \\\\\n",
    "\\frac{\\mathrm{d}G}{\\mathrm{d}t} &= -\\beta G + k_m G_u\n",
    "\\end{align*}$$\n",
    "\n",
    "The solution for the amount of mature protein $G(t)$ is:\n",
    "$$\n",
    "G(t) = G_0 \\mathrm{e}^{-\\beta t} + G_{u0}\\left(\\mathrm{e}^{-\\beta t} - \\mathrm{e}^{-(\\beta+k_m)t}\\right)\n",
    "$$\n",
    "The parameters to fit are $\\beta$, $k_m$ and $G_{u0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook structure\n",
    "The notebook has the following structure:\n",
    "\n",
    "At first, the model functions are defined and the data is loaded. The next section contains code for fitting the two models separately. The next section contains code for fitting the two traces in one run with parameters shared among the models.\n",
    "\n",
    "Fitting requires that the result list `R` is defined, which can be done by running the corresponding cell. When `R` has been populated by fitting, the results can be plotted. There are cells for plotting the results of the separate fit, the results of the combined fit, and the pure parameter distributions of all fits.\n",
    "\n",
    "Additionally, there are cells for saving and loading paramaters by python’s `pickle` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules needed\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Scientific stack\n",
    "import numpy as np\n",
    "np.seterr(divide='print')\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#import scipy as sc\n",
    "from scipy.cluster import hierarchy as ch\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42 # Make fonts editable by Adobe Illustrator\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Notebook utilities\n",
    "import IPython\n",
    "import ipywidgets as wdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define utility functions\n",
    "def getTimeStamp():\n",
    "    \"\"\"Returns a human-readable string representation of the current time\"\"\"\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    if os.name == 'nt':\n",
    "        # Cope with unicode incapability of time library in Windows\n",
    "        return '–'.join((now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H%M%S\")))\n",
    "    return now.strftime(\"%Y-%m-%d–%H%M%S\")\n",
    "\n",
    "\n",
    "def getOutpath(filename='', timestamp=None):\n",
    "    \"\"\"Returns (and creates, if necessary) the path to a directory\n",
    "    called “out” inside the current directory.\n",
    "    If `filename` is given, the filename is appended to the output directory.\n",
    "    A timestamp will be added to the filename if `timestamp != ''`.\n",
    "    If timestamp is `None`, the current timestamp is used.\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    outpath = os.path.join(os.getcwd(), 'out')\n",
    "    if not os.path.isdir(outpath) and not os.path.lexists(outpath):\n",
    "        os.mkdir(outpath)\n",
    "\n",
    "    # If requested, build filename\n",
    "    if len(filename) > 0:\n",
    "        if timestamp == None:\n",
    "            timestamp = getTimeStamp()\n",
    "        outpath = os.path.join(outpath, ((timestamp + '_') if len(timestamp) > 0 else '') + filename)\n",
    "    return outpath\n",
    "\n",
    "\n",
    "def getDataLabel(i, isFilename=False):\n",
    "    \"\"\"Returns a nicely formatted name for the `i`-th element of `D`.\n",
    "    Set `isFilename=True` for a filename-friendly output.\"\"\"\n",
    "    if isFilename:\n",
    "        return \"{0[measurement]}_{0[sample]}_{0[condition]}\".format(D[i])\n",
    "    return \"{0[sample]}: {0[condition]} [{0[measurement]}]\".format(D[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data and prepare result list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loading\n",
    "\n",
    "# Define available files\n",
    "datafiles = [\n",
    "    {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"rfp\",\n",
    "        \"measurement\": \"2017-09-08_seq6\",\n",
    "        \"file\": \"data/2017-09-08_seq6_Huh7_CayRFP_CHX_7h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"rfp\",\n",
    "        \"measurement\": \"2017-09-08_seq7\",\n",
    "        \"file\": \"data/2017-09-08_seq7_Huh7_CayRFP_CHX_7h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"rfp\",\n",
    "        \"measurement\": \"2017-09-08_seq8\",\n",
    "        \"file\": \"data/2017-09-08_seq8_Huh7_CayRFP_CHX_5h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"rfp\",\n",
    "        \"measurement\": \"2017-09-08_seq9\",\n",
    "        \"file\": \"data/2017-09-08_seq9_Huh7_CayRFP_CHX_5h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"rfp\",\n",
    "        \"measurement\": \"2017-09-08_seq10\",\n",
    "        \"file\": \"data/2017-09-08_seq10_Huh7_CayRFP_CHX_3h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"rfp\",\n",
    "        \"measurement\": \"2017-09-08_seq11\",\n",
    "        \"file\": \"data/2017-09-08_seq11_Huh7_CayRFP_CHX_3h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"gfp\",\n",
    "        \"measurement\": \"2017-08-18_seq6\",\n",
    "        \"file\": \"data/2017-08-18_seq6_Huh7_eGFP_CHX_7h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"gfp\",\n",
    "        \"measurement\": \"2017-08-18_seq7\",\n",
    "        \"file\": \"data/2017-08-18_seq7_Huh7_eGFP_CHX_7h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"gfp\",\n",
    "        \"measurement\": \"2017-08-18_seq8\",\n",
    "        \"file\": \"data/2017-08-18_seq8_Huh7_eGFP_CHX_5h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"gfp\",\n",
    "        \"measurement\": \"2017-08-18_seq9\",\n",
    "        \"file\": \"data/2017-08-18_seq9_Huh7_eGFP_CHX_5h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"gfp\",\n",
    "        \"measurement\": \"2017-08-18_seq10\",\n",
    "        \"file\": \"data/2017-08-18_seq10_Huh7_eGFP_CHX_3h.xlsx\"\n",
    "    }, {\n",
    "        \"sample\": \"Huh7\",\n",
    "        \"condition\": \"gfp\",\n",
    "        \"measurement\": \"2017-08-18_seq11\",\n",
    "        \"file\": \"data/2017-08-18_seq11_Huh7_eGFP_CHX_3h.xlsx\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# By default, mark all files for loading\n",
    "load_idcs = range(len(datafiles))\n",
    "\n",
    "# Define function for loading data\n",
    "def load_data_from_files():\n",
    "    \"\"\"Loads data from specified files into `D`.\n",
    "    Requires `load_idcs` to hold a list of indices to `datafiles`.\"\"\"\n",
    "    global D\n",
    "    D = []\n",
    "    for i in load_idcs:\n",
    "        # Show message\n",
    "        print(\"Loading file: {}\".format(datafiles[i][\"file\"]))\n",
    "\n",
    "        # Read sheets from excel file\n",
    "        X = pd.read_excel(datafiles[i]['file'], dtype=np.float64, sheet_name=0)\n",
    "\n",
    "        # Write data into easy-to-access structure\n",
    "        d = {}\n",
    "        d['sample'] = datafiles[i]['sample']\n",
    "        d['condition'] = datafiles[i]['condition']\n",
    "        d['measurement'] = datafiles[i]['measurement']\n",
    "        d['file'] = datafiles[i]['file']\n",
    "\n",
    "        d['t'] = X.values[:,0].flatten()\n",
    "        d['fluorescence'] = X.values[:,1:]\n",
    "        D.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in data from excel sheets\n",
    "\n",
    "# Prompt user for files to load\n",
    "lbl = wdg.Label('Select the files to load:')\n",
    "lbl.layout.width = 'initial'\n",
    "entries = []\n",
    "for f in datafiles:\n",
    "    entries.append(\"{} {}: {}\".format(\n",
    "        f['sample'], f['condition'], f['file']))\n",
    "sel_entry = wdg.SelectMultiple(options=entries, rows=len(entries))\n",
    "sel_entry.layout.width = 'initial'\n",
    "bload = wdg.Button(description='Load')\n",
    "bselall = wdg.Button(description='Select all')\n",
    "bselnone = wdg.Button(description='Select none')\n",
    "\n",
    "# Define callbacks\n",
    "def sel_all_files(_):\n",
    "    sel_entry.value = entries\n",
    "def sel_no_files(_):\n",
    "    sel_entry.value = ()\n",
    "def load_button_clicked(_):\n",
    "    global load_idcs\n",
    "    load_idcs = [entries.index(r) for r in sel_entry.value]\n",
    "    vb.close()\n",
    "    load_data_from_files()\n",
    "bselall.on_click(sel_all_files)\n",
    "bselnone.on_click(sel_no_files)\n",
    "bload.on_click(load_button_clicked)\n",
    "\n",
    "# Finally, show the widgets\n",
    "vb = wdg.VBox((lbl, sel_entry, wdg.HBox((bload,bselall,bselnone))))\n",
    "IPython.display.display(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide output tables\n",
    "\n",
    "# Initialize result list\n",
    "R = []\n",
    "\n",
    "# Iteratively populate the result dictionary\n",
    "for k in range(len(D)):\n",
    "    nTimes, nTraces = np.shape(D[k]['fluorescence'])\n",
    "    R.append(np.full((nTraces,), np.NaN, dtype=[('t0', 'f8'), ('nInit', 'u2')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle or load fitting results\n",
    "Pickling is only reasonable if the result list `R` has already been populated by fitting (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle fit results for future sessions\n",
    "outfile = getOutpath('fixed_fit_results.pickled')\n",
    "with open(outfile, 'wb') as f:\n",
    "    pickle.dump(R, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pickled results (requires file suffix “.pickled”)\n",
    "pickfiles = [f for f in os.listdir(getOutpath()) if f.lower().endswith('.pickled')]\n",
    "pickfiles.sort(reverse=True)\n",
    "\n",
    "lbl = wdg.Label('Select the file to load:')\n",
    "lbl.layout.width = 'initial'\n",
    "rad = wdg.RadioButtons(options=pickfiles)\n",
    "but = wdg.Button(description='Load')\n",
    "vb = wdg.VBox([lbl, rad, but])\n",
    "IPython.display.display(vb)\n",
    "\n",
    "def clicked_on_but(b):\n",
    "    global R\n",
    "    with open(getOutpath(rad.value, ''), 'rb') as f:\n",
    "        R = pickle.load(f)\n",
    "    print('Loaded: ' + rad.value)\n",
    "    vb.close()\n",
    "but.on_click(clicked_on_but)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to XLSX\n",
    "if len(R) != len(D):\n",
    "    raise ValueError(\"R and D must have the same length!\")\n",
    "\n",
    "# Set up XLSX writer\n",
    "file = getOutpath(\"CHX_onset_cluster.xlsx\")\n",
    "xlsx_writer = pd.ExcelWriter(file, engine='xlsxwriter')\n",
    "\n",
    "# Write each datafile into its sheet\n",
    "for k in range(len(D)):\n",
    "    datalabel = getDataLabel(k, True)\n",
    "    pd.DataFrame(R[k]).to_excel(xlsx_writer, sheet_name=datalabel, na_rep='NaN')\n",
    "    \n",
    "xlsx_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find onset by clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Z(time, data, isTimeNormalized=False, time_scale=20):\n",
    "    \"\"\"Finds the onset time by legacy algorithm. Not robust on new data.\n",
    "\n",
    "    Input parameters:\n",
    "        time: numpy vector of times of datapoints (in hours)\n",
    "        data: numpy vector of fluorescence intensity\n",
    "        isTimeNormalized: boolean indicating wheter `time` is normalized already\n",
    "        time_scale: scaling factor by which to divide the normalized time\n",
    "\n",
    "    Return value:\n",
    "        Z: the cluster tree returned by `linkage`\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalized time (in hours/`time_scale`)\n",
    "    if not isTimeNormalized:\n",
    "        tn = (time - time.min()) / (time.max() - time.min()) / time_scale\n",
    "    else:\n",
    "        tn = time\n",
    "\n",
    "    # Normalized data\n",
    "    dn = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "    # Gradient of normalized data\n",
    "    gradn = np.empty(np.shape(dn))\n",
    "    gradn[1:] = (dn[1:] - dn[:-1]) / (time[1:] - time[:-1])\n",
    "    gradn[0] = gradn[1]\n",
    "    gradn[gradn < 0] = 0\n",
    "\n",
    "    # Combine to observation matrix\n",
    "    tab = np.array([tn, dn, gradn]).T\n",
    "\n",
    "    # Perform clustering\n",
    "    Z = ch.linkage(tab, method='single', metric='cityblock')\n",
    "    return Z\n",
    "\n",
    "\n",
    "def get_t0(Z, time, height=0.025):\n",
    "    \"\"\"Finds the onset time and the clusters before it by the legacy algorithm\n",
    "\n",
    "    Input parameters:\n",
    "        Z: the cluster tree returned by `linkage`\n",
    "        time: numpy vector of times of datapoints (in hours)\n",
    "        height: threshold at which to cut cluster tree\n",
    "\n",
    "    Return value:\n",
    "        t0: the onset time found\n",
    "    \"\"\"\n",
    "    # Find last time point in initial cluster\n",
    "    ct = ch.cut_tree(Z, height=height).flatten()\n",
    "    t0 = time[ct == ct[0]][-1]\n",
    "    return t0\n",
    "\n",
    "\n",
    "def getBranchTime(b, Z, time):\n",
    "    \"\"\"Returns the time corresponding to a cluster node\n",
    "        b: node index (zero-based)\n",
    "        Z: cluster tree as returned from scipy.cluster.hierarchy.linkage\n",
    "        time: the time vector of measurements\"\"\"\n",
    "    nLeaves = time.size\n",
    "    b = int(b)\n",
    "    if b < nLeaves:\n",
    "        return time[b]\n",
    "    else:\n",
    "        b -= nLeaves\n",
    "        t1 = getBranchTime(Z[b,0], Z, time)\n",
    "        t2 = getBranchTime(Z[b,1], Z, time)\n",
    "        return (t1 + t2) / 2\n",
    "\n",
    "\n",
    "def climb_up(c, Z):\n",
    "    \"\"\"Climbs cluster hierarchy up by one step.\n",
    "\n",
    "    Input parameters:\n",
    "        c: cluster to start from\n",
    "        Z: cluster tree (from `linkage`)\n",
    "\n",
    "    Returns:\n",
    "        index of the cluster containing cluster `c`, or empty array if no cluster found\n",
    "    \"\"\"\n",
    "    return np.flatnonzero(np.any(Z[:,:2] == c, axis=1)) + Z.shape[0] + 1\n",
    "\n",
    "\n",
    "def climb_down(c, Z):\n",
    "    \"\"\"Climbs cluster hierarchy down by one step.\n",
    "\n",
    "    Input parameters:\n",
    "        c: cluster to start from\n",
    "        Z: cluster tree (from `linkage`)\n",
    "\n",
    "    Returns:\n",
    "        array of indices of child clusters, or empty array if no child clusters found\n",
    "    \"\"\"\n",
    "    c -= Z.shape[0] + 1\n",
    "    if c < 0:\n",
    "        return np.empty((0), dtype=np.intp)\n",
    "    else:\n",
    "        return Z[c,:2].astype(np.intp)\n",
    "\n",
    "\n",
    "def initial_clusters(Z, height=0.025):\n",
    "    \"\"\"Returns a boolean array indicating nodes belonging to initial cluster\n",
    "\n",
    "    Input parameters:\n",
    "        Z: cluster tree (from `linkage`)\n",
    "        height: maximum height of initial cluster\n",
    "\n",
    "    Returns:\n",
    "        boolean array of size `Z.shape[0] * 2 + 1`, such that the i-th value is\n",
    "        `True` iff the i-th cluster belongs to the initial cluster\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    nLeaves = Z.shape[0] + 1\n",
    "    isInitial = np.zeros((nLeaves * 2 - 1), dtype=np.bool_)\n",
    "    maxInitial = np.zeros(1, dtype=np.intp)\n",
    "\n",
    "    # Climb up to highest node in initial cluster\n",
    "    while True:\n",
    "        newMax = climb_up(maxInitial, Z)\n",
    "        if newMax.size == 0:\n",
    "            break\n",
    "        elif Z[newMax - nLeaves, 2] > height:\n",
    "            break\n",
    "        else:\n",
    "            maxInitial = newMax\n",
    "\n",
    "    # Recursively set entries for all nodes in initial cluster to `True`\n",
    "    inits = maxInitial.tolist()\n",
    "    for i in inits:\n",
    "        isInitial[i] = True\n",
    "        inits.extend(climb_down(i, Z).tolist())\n",
    "\n",
    "    return isInitial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get onset times by clustering\n",
    "\n",
    "def clustering(time, data, height=0.025, iTrace=None, dataset=None, pdf=None, isShow=True):\n",
    "    \"\"\"\n",
    "    Find t0 and plot to PDF\n",
    "    \"\"\"\n",
    "    # Find t0 by clustering\n",
    "    Z = get_Z(time, data)\n",
    "    t0 = get_t0(Z, time, height=height)\n",
    "\n",
    "    # Write array indicating initial cluster\n",
    "    isInitial = initial_clusters(Z, height=height)\n",
    "    nInitial = np.sum(isInitial, dtype=np.uint16)\n",
    "\n",
    "    # Create plot if requested\n",
    "    if isShow or pdf is not None:\n",
    "        nLeaves = time.size\n",
    "\n",
    "        # Create figure to plot to\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(2, 1, 1)\n",
    "        ax2 = fig.add_subplot(2, 1, 2, sharex=ax1)\n",
    "        fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "        # Indicate onset time\n",
    "        ax1.axvline(t0, color='r')\n",
    "        ax2.axvline(t0, color='r')\n",
    "\n",
    "        # Indicate maximum height of initial cluster\n",
    "        ax2.axhline(height, color='k', ls='--', lw=.5)\n",
    "\n",
    "        # Plot trace with t0\n",
    "        ax1.plot(time, data, '-k')\n",
    "\n",
    "        # Get minimum of trace\n",
    "        trace_min = data.min()\n",
    "\n",
    "        # Plot vertical lines below graph\n",
    "        for t in range(nLeaves):\n",
    "            if isInitial[t]:\n",
    "                clr = 'm'\n",
    "            else:\n",
    "                clr = 'b'\n",
    "            ax1.plot([time[t], time[t]], [data[t], trace_min],\n",
    "                     '-', color=clr, linewidth=.5, clip_on=False)\n",
    "            ax1.plot(time[t], data[t],\n",
    "                    'o', color=clr, markersize=2, clip_on=False)\n",
    "\n",
    "        # Plot custom dendrogram because built-in dendrogram does\n",
    "        # not allow for custom ordering of leaves\n",
    "        for z in range(Z.shape[0]):\n",
    "            b1, b2 = (Z[z,0], Z[z,1]) if Z[z,0] < Z[z,1] \\\n",
    "                else (Z[z,1], Z[z,0])\n",
    "            b1 = int(b1)\n",
    "            b2 = int(b2)\n",
    "            h1 = 0 if b1 < nLeaves else Z[b1-nLeaves,2]\n",
    "            h2 = 0 if b2 < nLeaves else Z[b2-nLeaves,2]\n",
    "            t1 = getBranchTime(b1, Z, time)\n",
    "            t2 = getBranchTime(b2, Z, time)\n",
    "\n",
    "            node = np.empty((4, 2))\n",
    "            node[0,:] = [t1, h1]\n",
    "            node[1,:] = [t1, Z[z,2]]\n",
    "            node[2,:] = [t2, Z[z,2]]\n",
    "            node[3,:] = [t2, h2]\n",
    "\n",
    "            if isInitial[z + nLeaves]:\n",
    "                clr = 'm'\n",
    "            else:\n",
    "                clr = 'b'\n",
    "            ax2.plot(node[:,0], node[:,1], '-',\n",
    "                     color=clr, linewidth=.5)\n",
    "\n",
    "        # Format figure\n",
    "        ax1.tick_params('x', bottom=False, labelbottom=False)\n",
    "        ax1.set_ylim(bottom=trace_min)\n",
    "\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.set_ylim(top=0)\n",
    "        ax2.set_yscale('symlog', linthreshy=0.001, linscaley=.5)\n",
    "        ax1.set_axisbelow(True)\n",
    "        ax2.set_axisbelow(True)\n",
    "\n",
    "        ax2.set_xlabel('Time [h]')\n",
    "        ax1.set_ylabel('Fluorescence [a.u.]')\n",
    "        ax2.set_ylabel('Distance [a.u.]')\n",
    "\n",
    "        suptitle = []\n",
    "        if dataset is not None:\n",
    "            suptitle.append(dataset)\n",
    "        if iTrace is not None:\n",
    "            suptitle.append(\"Trace {:03d}\".format(iTr))\n",
    "        fig.suptitle('\\n'.join(suptitle))\n",
    "\n",
    "        if pdf is not None:\n",
    "            pdf.savefig(fig)\n",
    "        if isShow:\n",
    "            plt.show(fig)\n",
    "        plt.close(fig)\n",
    "        fig.clear()\n",
    "\n",
    "    return t0, nInitial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get onset times by clustering\n",
    "ts = getTimeStamp()\n",
    "isShow = 0\n",
    "\n",
    "for iD, d in enumerate(D):\n",
    "    datalabel = getDataLabel(iD)\n",
    "    time = d['t']\n",
    "    data = d['fluorescence']\n",
    "    with PdfPages(getOutpath(\"ONSET_CLUSTER_{}.pdf\".format(getDataLabel(iD, True)), ts)) as pdf:\n",
    "        for iTr in range(data.shape[1]):\n",
    "            t0, nInitial = clustering(time, data[:,iTr], iTrace=iTr, dataset=datalabel,\n",
    "                                      pdf=pdf, isShow=True)\n",
    "\n",
    "            # Save to results list\n",
    "            R[iD][iTr] = t0, nInitial\n",
    "\n",
    "            # Avoid notebook crash by too many figures\n",
    "            if isShow:\n",
    "                if isShow < 200:\n",
    "                    isShow += 1\n",
    "                else:\n",
    "                    isShow = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify ill-shaped raw traces\n",
    "For these measurements, the parts before CHX addition were cut away from the traces.\n",
    "While most traces now start with an ascend, some traces have minima after the first value.\n",
    "As our fitting model does not account for this behaviour, such traces may be fitted badly and affect the mean parameter values.\n",
    "\n",
    "We therefore want to identify those traces and sort them out.\n",
    "\n",
    "A trace is treated as ill-shaped if its smallest value before the maximum is\n",
    "* the third or a later value or\n",
    "* the second value and\n",
    "  * its difference to the first value is larger than 3% of its difference to the maximum or\n",
    "  * another value before the maximum is smaller than the first value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_traces(data):\n",
    "    \"\"\"\n",
    "    Finds ill-shaped traces. A trace is ill-shaped or bad if\n",
    "    any value before the maximum is smaller than the first value.\n",
    "    However, if only the second value is smaller than the first value\n",
    "    and the difference between first and second value does not exceed\n",
    "    a threshold (3%) of the difference between maximum value and\n",
    "    minimum value, the trace is not assumed bad.\n",
    "\n",
    "    Argument:\n",
    "        data -- array of traces (columns: traces, row: timepoints)\n",
    "\n",
    "    Returns:\n",
    "        1-dim indexing array, where the i-th element indicates if\n",
    "        the i-th trace from data is bad (True) or not (False).\n",
    "    \"\"\"\n",
    "    # Find maxima and minima of the traces\n",
    "    maxima = data.argmax(axis=0)\n",
    "    minima = np.zeros_like(maxima)\n",
    "    for i, m in enumerate(maxima):\n",
    "        minima[i] = data[:m,i].argmin(axis=0)\n",
    "\n",
    "    # Mark all traces as bad where the first value is not the minimum\n",
    "    bad_traces = minima > 0\n",
    "\n",
    "    for i, m in enumerate(minima):\n",
    "        # If only the second value is smaller than the first …\n",
    "        if (m == 1) and data[2:maxima[i],i].min() > data[0,i]:\n",
    "            # … check if the relative difference exceeds a threshold …\n",
    "            amp = data[maxima[i],i] - data[m,i]\n",
    "            if (data[0,i] - data[1,i]) / amp <= 0.3:\n",
    "                # … and if not, do not discard the trace\n",
    "                bad_traces[i] = False\n",
    "\n",
    "    return bad_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for bad traces\n",
    "bad_traces_red = pd.DataFrame(False, index=chsq_red.index, columns=('bad',), dtype=np.bool_)\n",
    "bad_traces_green = pd.DataFrame(False, index=chsq_green.index, columns=('bad',), dtype=np.bool_)\n",
    "\n",
    "for i, d in enumerate(D):\n",
    "    condition = d['condition']\n",
    "    data = d[condition]\n",
    "\n",
    "    # Identify bad traces:\n",
    "    # the minimum is before the maximum, but not the first point\n",
    "    #minima = data.argmin(axis=0)\n",
    "    #maxima = data.argmax(axis=0)\n",
    "    #bad_traces = (minima > 0) & (minima < maxima)\n",
    "    bad_traces = find_bad_traces(data)\n",
    "\n",
    "    # Save bad traces in condition-specific table\n",
    "    if condition == 'rfp':\n",
    "        bad_traces_red.loc[i, 'bad'] = bad_traces\n",
    "    elif condition == 'gfp':\n",
    "        bad_traces_green.loc[i, 'bad'] = bad_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bad traces\n",
    "with PdfPages(getOutpath(\"fixed_bad_traces.pdf\")) as pdf:\n",
    "    for condition in (\"rfp\", \"gfp\"):\n",
    "        if condition == 'rfp':\n",
    "            bad_traces = bad_traces_red\n",
    "        elif condition == 'gfp':\n",
    "            bad_traces = bad_traces_green\n",
    "\n",
    "        for i, j in bad_traces.index:\n",
    "            if not bad_traces.loc[(i,j),'bad']:\n",
    "                continue\n",
    "\n",
    "            clr = condition[0]\n",
    "            t = D[i]['t']\n",
    "\n",
    "            f, ax = plt.subplots(1, 1)\n",
    "            ax.plot(t, D[i][condition][:,j], '-', color=clr, lw=1, label=\"measured\")\n",
    "            ax.plot(t, R[i][condition]['fit'][:,j], '-k', lw=0.5, label=\"best fit\")\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(\"Time [h]\")\n",
    "            ax.set_ylabel(\"Fluorescence [a.u.]\")\n",
    "            ax.set_title(\"Trace {:03d} in {}\".format(j, getDataLabel(i)))\n",
    "\n",
    "            f.tight_layout(pad=0)\n",
    "            plt.show(f)\n",
    "            pdf.savefig(f)\n",
    "            plt.close(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
